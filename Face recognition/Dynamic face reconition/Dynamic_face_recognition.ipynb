{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dynamic face recognition.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3mf2g_wbrl8"
      },
      "source": [
        "import face_recognition\r\n",
        "import cv2\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "from google.colab.patches import cv2_imshow\r\n",
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kek9Z8v6bzLv"
      },
      "source": [
        "# Open the input movie file\r\n",
        "input_movie = cv2.VideoCapture(\"test.mp4\")\r\n",
        "length = int(input_movie.get(cv2.CAP_PROP_FRAME_COUNT))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8Tyj708b1az"
      },
      "source": [
        "# Create an output movie file (make sure resolution/frame rate matches input video!)\r\n",
        "fourcc = cv2.VideoWriter_fourcc(*'XVID')\r\n",
        "output_movie = cv2.VideoWriter('output.avi', fourcc, 29.97, (426, 240))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhpaUYxIb3Xh"
      },
      "source": [
        "def get_encoded_faces():\r\n",
        "    \"\"\"\r\n",
        "    looks through the faces folder and encodes all\r\n",
        "    the faces\r\n",
        " \r\n",
        "    :return: dict of (name, image encoded)\r\n",
        "    \"\"\"\r\n",
        "    encoded = {}\r\n",
        " \r\n",
        "    for dirpath, dnames, fnames in os.walk(\"./faces\"):\r\n",
        "        for f in fnames:\r\n",
        "            if f.endswith(\".jpg\") or f.endswith(\".png\"):\r\n",
        "                face = face_recognition.load_image_file(\"faces/\" + f)\r\n",
        "                encoding = face_recognition.face_encodings(face)[0]\r\n",
        "                encoded[f.split(\".\")[0]] = encoding\r\n",
        "    return encoded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Su4YnOQ7b7uE"
      },
      "source": [
        "def unknown_image_encoded(img):\r\n",
        "    \"\"\"\r\n",
        "    encode a face given the file name\r\n",
        "    \"\"\"\r\n",
        "    face = fr.load_image_file(\"faces/\" + img)\r\n",
        "    encoding = fr.face_encodings(face)[0]\r\n",
        " \r\n",
        "    return encoding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Id41eYLxcLLz"
      },
      "source": [
        "# Initialize some variables\r\n",
        "face_locations = []\r\n",
        "face_encodings =[]\r\n",
        "faces = get_encoded_faces()\r\n",
        "known_face_encodings = list(faces.values())\r\n",
        "known_face_names = list(faces.keys())\r\n",
        "frame_number = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlZbmL-NcL7i"
      },
      "source": [
        "while True:\r\n",
        "    # Grab a single frame of video\r\n",
        "    ret, frame = input_movie.read()\r\n",
        "    frame_number += 1\r\n",
        "\r\n",
        "    # Quit when the input video file ends\r\n",
        "    if not ret:\r\n",
        "        break\r\n",
        "\r\n",
        "    # Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses)\r\n",
        "    rgb_frame = frame[:, :, ::-1]\r\n",
        "\r\n",
        "    # Find all the faces and face encodings in the current frame of video\r\n",
        "    face_locations = face_recognition.face_locations(rgb_frame)\r\n",
        "    face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\r\n",
        "\r\n",
        "    face_names = []\r\n",
        "    for face_encoding in face_encodings:\r\n",
        "        # See if the face is a match for the known face(s)\r\n",
        "        matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\r\n",
        "        name = \"Unknown\"\r\n",
        "\r\n",
        "            # # If a match was found in known_face_encodings, just use the first one.\r\n",
        "            # if True in matches:\r\n",
        "            #     first_match_index = matches.index(True)\r\n",
        "            #     name = known_face_names[first_match_index]\r\n",
        "\r\n",
        "            # Or instead, use the known face with the smallest distance to the new face\r\n",
        "        face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\r\n",
        "        best_match_index = np.argmin(face_distances)\r\n",
        "        if matches[best_match_index]:\r\n",
        "            name = known_face_names[best_match_index]\r\n",
        "            acc = np.array(known_face_encodings[best_match_index] / face_encoding)*100\r\n",
        "            accuracy = round(np.mean(acc),2)\r\n",
        "            acc_text = \"{}%\".format(accuracy)\r\n",
        "\r\n",
        "        face_names.append(name)\r\n",
        "\r\n",
        "    # Label the results\r\n",
        "    for (top, right, bottom, left), name in zip(face_locations, face_names):\r\n",
        "        if not name:\r\n",
        "            continue\r\n",
        "\r\n",
        "        # Draw a box around the face\r\n",
        "        if name == \"Unknown\":\r\n",
        "          cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\r\n",
        "        else:\r\n",
        "          cv2.rectangle(frame, (left, top), (right, bottom), (255, 0, 0), 2)\r\n",
        "\r\n",
        "        # Draw a label with a name below the face\r\n",
        "        if name == \"Unknown\":\r\n",
        "          cv2.rectangle(frame, (left, bottom - 25), (right, bottom), (0, 0, 255), cv2.FILLED)\r\n",
        "        else:\r\n",
        "          cv2.rectangle(frame, (left, bottom - 25), (right, bottom), (255, 0, 0), cv2.FILLED)\r\n",
        "        font = cv2.FONT_HERSHEY_COMPLEX\r\n",
        "        cv2.putText(frame, name, (left + 6, bottom - 6), font, 0.5, (255, 255, 255), 1)\r\n",
        "        #cv2.putText(frame, acc_text, (right - 6,bottom + 6), font,1.0, (255,255,255),1)\r\n",
        "\r\n",
        "    # Write the resulting image to the output video file\r\n",
        "    print(\"Writing frame {} / {}\".format(frame_number, length))\r\n",
        "    output_movie.write(frame)\r\n",
        "\r\n",
        "    \r\n",
        "    key = cv2.waitKey(1) & 0xFF\r\n",
        "\t  # if the `q` key was pressed, break from the loop\r\n",
        "    if key == ord(\"q\"):\r\n",
        "      break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4N6ge0IcvbP"
      },
      "source": [
        "# do a bit of cleanup\r\n",
        "print(\"[INFO] cleaning up...\")\r\n",
        "cv2.destroyAllWindows()\r\n",
        "output_movie.release()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}